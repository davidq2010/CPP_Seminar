////////////////////////////////////////////////////////////////////////////////
/// @file
/// @brief Brief overview of concurrency.
///
/// CAVEAT - This is not a parallel or multi-threaded class. I will do my best
///          to answer questions, but most of them I will unfortunately say,
///          that it is beyond the scope of this class/material. I recommend
///          googling the definitions of terminology that I use to learn more.
///
/// Outline
///  - Definitions and STL support of concurrency
///  - Miscellaneous advice
///  - Example
////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////
/// Definitions and STL support of concurrency
///
/// - Core (processor) - a hardware CPU unit capable of general computation.
/// - Hardware thread - a subpiece of the core that can actually run
///   computation, hardware can possibly have more than one per core. Important
///   that #threads != #cores.
/// - System thread - thread "objects" manages by the operating system.
///   Important that #hardware threads != #sytem threads.
/// - std::thread - A C++ library component that is agnostic to the specific
///   underlying system. Essentially, you should always use std::threads instead
///   of older system specific libraries because of this.
/// - Think of threads as pieces of computations.
///
/// - Multi-threaded computation - a computation that interleaves execution
///   between multiple threads. This is not the same as parallel and simply
///   appears to be parallel as both threads operate at the same time.
/// - Parallel computation - a truly concurrent (at the same time) computation
///   occuring on separate cores (or within the same core as the same time).
///
/// - Thread-based approaches are manual and threads cannot return values to a
///   caller. This uses std::thread.
/// - Tasked-based approaches are more streamlined and abstract the mapping from
///   function to thread and leave that to the runtime system. These are capable
///   of returning values to a caller. This uses std::async.
///
/// - Future (std::future) - a value generated by an asynchronous operation. It
///   is  named this way because it will provide an answer at a future time,
///   when the asynchronous operation finishes.
/// - Promise (std::promise) - a location for an asynchronous task to store a
///   value and a future to access that value when ready.
///
/// - Race condition - two or more threads/parallel computations reading/writing
///   simultenously to the same data in which the order of operations matters
///   for correctness.
/// - Mutex (std::mutex) - Mutual exclusion object. These are locked (std::lock)
///   and unlocked by various threads or parallel computations to restrict
///   access of data (or code sections) to one (or more) accessors. Useful in
///   avoiding race conditions.
/// - Atomics - data types that grouped reading and writing to a data location.
///   Useful in avoiding race conditions and the cost of mutex locking.
///
/// - C++11/14 have basic building blocks (named).
/// - C++17/20 have an extensive parallel algorithm addition.
///
/// - AND MORE!
////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////
/// Miscellaneous advice
///
/// - Prefer std::async and tasked-based parallelism. MUCH easier to reason
///   about. Much more convenient for programming. Puts onus on compiler writer
///   and library developers to figure out the hard stuff. Use threading for
///   specific things, e.g., you need to further optimize thread usage in your
///   system.
/// - When starting an asynchronous task, prefer using std::launch::async to
///   ensure it is truly asynchronous.
/// - Pitfalls
///   - Understand destructor behavior of futures and threads. There is no good
///     option and lots of issues when they go out of scope before finishing.
///   - Make all threads "unjoinable" -- learn what "joinable" means and
///     destructor behavior to understand this further.
///   - To communicate between threads in a one-shot fashion consider a void
///     future.
///   - volatile != atomic. Atomic is about combining reads and writes so they
///     are not separated when threads are interleaved. Volatile is for special
///     memory to turn off compiler optimizations.
/// - Take a parallel or OS class as some point in your life!
////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////
/// Example
///
/// - Parallel average of an array below
////////////////////////////////////////////////////////////////////////////////

#include <algorithm>
#include <array>
#include <chrono>
#include <future>
#include <iostream>
#include <random>

///////////////////////////////////////
/// @brief Main driver
/// @return Success/failure
int
main() {
  // Generate array of random values
  std::default_random_engine generator;
  std::uniform_real_distribution<double> distribution(-1.0, 1.0);

  constexpr size_t SZ = 1'000'000;
  std::array<double, SZ> arr;
  std::generate(arr.begin(), arr.end(),
    [&distribution, &generator]() { return distribution(generator); }
  );

  using my_clock = std::chrono::high_resolution_clock;
  using seconds = std::chrono::duration<float>;
  // Sequential summation
  my_clock::time_point start = my_clock::now();

  double avg1 = 0;
  for(size_t r = 0; r < 10000; ++r) // Repeating 10000 times is for dramatic effect
    avg1 = std::accumulate(arr.begin(), arr.end(), 0.)/SZ;

  double time1 = std::chrono::duration_cast<seconds>(
    my_clock::now() - start
  ).count();
  std::cout << "Time: " << time1 << "\tAverageS: " << avg1 << std::endl;

  // Lambda expression for task to partially sum array from _i to _j
  auto sum = [&arr](size_t _i, size_t _j) {
    double s = 0;
    for(size_t r = 0; r < 10000; ++r) { // Repeating 10000 times is for dramatic effect
      s = 0;
      for(size_t i = _i; i < _j; ++i)  // Repeating 10000 times is for dramatic effect
        s += arr[i];
    }
    return s;
  };

  // Spark 4 asynchronous tasks on four parts of the array.
  // Each is stored in a future (in this case std::future<double>).
  // get will wait for the task to finish.
  start = my_clock::now();

  auto s0 = std::async(std::launch::async, sum, 0, SZ/4);
  auto s1 = std::async(std::launch::async, sum, SZ/4, SZ/2);
  auto s2 = std::async(std::launch::async, sum, SZ/2, 3*SZ/4);
  auto s3 = std::async(std::launch::async, sum, 3*SZ/4, SZ);
  double avg2 = (s0.get() + s1.get() + s2.get() + s3.get())/SZ;

  double time2 = std::chrono::duration_cast<seconds>(
    my_clock::now() - start
  ).count();
  std::cout << "Time: " << time2 << "\tAverageP: " << avg2 << std::endl;
}